2024-11-19 19:06:53,495 - INFO - Deleted old log file: logs/lstm_log_2024-11-19_18-33-47.log
2024-11-19 19:06:53,496 - INFO - Starting LSTM model script
2024-11-19 19:06:53,496 - INFO - Loading and preparing data
2024-11-19 19:07:00,707 - INFO - Data overview: count     181.000000
mean     1184.917127
std       358.869597
min       645.000000
25%       878.000000
50%      1099.000000
75%      1512.000000
max      1962.000000
Name: transaction_qty, dtype: float64
2024-11-19 19:07:00,708 - INFO - Training data size: 136, Testing data size: 35
2024-11-19 19:07:00,708 - INFO - Starting with initial best parameters: {'num_units': 262, 'batch_size': 1, 'epochs': 150}
2024-11-19 19:07:00,708 - INFO - Testing num_units=212
2024-11-19 19:08:17,960 - INFO - num_units=212 - MAE: 120.89, RMSE: 149.65, Final Val Loss: 0.0066
2024-11-19 19:08:17,960 - INFO - Testing num_units=237
2024-11-19 19:09:40,393 - INFO - num_units=237 - MAE: 99.71, RMSE: 134.88, Final Val Loss: 0.0060
2024-11-19 19:09:40,394 - INFO - Testing num_units=262
2024-11-19 19:11:06,609 - WARNING - 5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x308538700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
2024-11-19 19:11:06,678 - WARNING - 6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x308538700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
2024-11-19 19:11:06,681 - INFO - num_units=262 - MAE: 107.36, RMSE: 143.57, Final Val Loss: 0.0041
2024-11-19 19:11:06,681 - INFO - Testing num_units=287
2024-11-19 19:12:41,173 - INFO - num_units=287 - MAE: 148.81, RMSE: 173.30, Final Val Loss: 0.0111
2024-11-19 19:12:41,174 - INFO - Testing num_units=312
2024-11-19 19:14:21,592 - INFO - num_units=312 - MAE: 116.02, RMSE: 145.29, Final Val Loss: 0.0055
2024-11-19 19:14:26,243 - INFO - Best num_units found: 237 with RMSE: 134.88
2024-11-19 19:14:26,244 - INFO - Skipping already tested combination: {'num_units': 237, 'batch_size': 1, 'epochs': 150}
2024-11-19 19:14:26,244 - INFO - Skipping already tested combination: {'num_units': 237, 'batch_size': 1, 'epochs': 150}
2024-11-19 19:14:26,244 - INFO - Skipping already tested combination: {'num_units': 237, 'batch_size': 1, 'epochs': 150}
2024-11-19 19:14:26,244 - INFO - Testing batch_size=9
2024-11-19 19:14:43,680 - INFO - batch_size=9 - MAE: 111.79, RMSE: 153.01, Final Val Loss: 0.0061
2024-11-19 19:14:43,681 - INFO - Testing batch_size=17
2024-11-19 19:14:55,706 - INFO - batch_size=17 - MAE: 120.09, RMSE: 160.40, Final Val Loss: 0.0061
2024-11-19 19:15:01,630 - INFO - Best batch_size found: 9 with RMSE: 153.01
2024-11-19 19:15:01,630 - INFO - Testing epochs=100
2024-11-19 19:15:13,303 - INFO - epochs=100 - MAE: 108.91, RMSE: 140.59, Final Val Loss: 0.0064
2024-11-19 19:15:13,304 - INFO - Testing epochs=125
2024-11-19 19:15:31,357 - INFO - epochs=125 - MAE: 101.90, RMSE: 140.08, Final Val Loss: 0.0061
2024-11-19 19:15:31,358 - INFO - Skipping already tested combination: {'num_units': 237, 'batch_size': 9, 'epochs': 150}
2024-11-19 19:15:31,358 - INFO - Testing epochs=175
2024-11-19 19:15:57,269 - INFO - epochs=175 - MAE: 112.03, RMSE: 138.04, Final Val Loss: 0.0057
2024-11-19 19:15:57,270 - INFO - Testing epochs=200
2024-11-19 19:16:23,835 - INFO - epochs=200 - MAE: 123.73, RMSE: 146.29, Final Val Loss: 0.0073
2024-11-19 19:16:35,317 - INFO - Best epochs found: 175 with RMSE: 138.04
2024-11-19 19:16:35,319 - INFO - Best parameters updated and saved to params/best_lstm_params.json
2024-11-19 19:16:35,321 - INFO - Deleted old model file: models/best_lstm_model.keras
2024-11-19 19:17:03,940 - INFO - Best model saved to models/best_lstm_model.keras
